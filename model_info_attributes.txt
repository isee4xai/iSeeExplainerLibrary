==================================================================
Mandatory attributes:

alias => string with the name given to the model
backend => "sklearn", "TF1", "TF2", "PYT", or "other"
model_task => "classification", "regression", or "other"
datatype => "Image", "Tabular", or "Text"

==================================================================
For classification models:

(Optional) output_names => Array of strings with the names of the target classes in order.

==================================================================
For tabular data:

categorical_names => Dictionary with indexes of categorical columns as keys and arrays of strings containing the categorical values as values.
categorical_features => Array of ints representing the indexes of the categorical columns. Columns not included here will be considered continuous.
cont_features => array of strings with the names of the continuous features
ohe => Boolean value to indicate if the data is one-hot encoded
(Optional) target_name  => target variable name
(Optional) feature_names => Array of strings with the names of the features in order.
Only if dataset was not uploaded: features => JSON Object with feature names as keys and arrays containing the ranges of continuous features, or strings with the categories for categorical features.

==================================================================
For timeseries models:

target_columns => array containing the indexes of the target columns of the dataset. 

==================================================================
For Image Normalization in Pytorch: (used for grad-cam)

mean: Array of floats used to normalize each channel of the RGB Image.
std: Array of floats used to normalize each channel of the RGB Image.

==================================================================
For pytorch-models: (used-for grad-cam)

target_layer: name of target layer to be provided as a string. This is the layer that you want to compute the visualization for.
	Usually this will be the last convolutional layer in the model. It is also possible to specify internal components of this layer by 	passing the target_layer_index parameter in params when making a call to the explainer resource. To get the target layer, this method executes 'model.<target_layer>	[<target_layer_index>]'
	Some common examples of these parameters for well-known models:
	Resnet18 and 50: model.layer4 -> 'target_layer':'layer4'
	VGG, densenet161: model.features[-1] -> 'target_layer':'features', 'target_layer_index':-1
	mnasnet1_0: model.layers[-1] -> 'target_layer':'layers', 'target_layer_index':-1
