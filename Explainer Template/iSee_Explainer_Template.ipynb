{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# iSee Explainer Template"
      ],
      "metadata": {
        "id": "-9y_8nLAk4Rm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Load sample model, data and additional information"
      ],
      "metadata": {
        "id": "7W5sTfsYk7LQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We support models with different implementation frameworks such as Scikit-learn, Tensorflow, Pytorch and others. You can load your model by using the recommended approach of your framework."
      ],
      "metadata": {
        "id": "g_VCymgjt5Nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOADING MODEL #\n",
        "#################\n",
        "\n",
        "#######\n",
        "# TODO:\n",
        "# Load your model file here. \n",
        "# You may do so via google drive\n",
        "#######\n",
        "model_file=None \n",
        "\n",
        "\n",
        "\n",
        "#######\n",
        "# TODO:\n",
        "# Choose how to load your model. \n",
        "# Comment the rest of options\n",
        "#######\n",
        "\n",
        "# For scikit-learn\n",
        "import joblib\n",
        "model=joblib.load(model_file)\n",
        "\n",
        "# For tensorflow\n",
        "import tensorflow as tf\n",
        "model=tf.keras.models.load_model(model_file)\n",
        "\n",
        "#For Pytorch\n",
        "import torch\n",
        "model=torch.load(model_file)\n",
        "\n",
        "# For different implementations, please make sure the model object can be loaded with joblib\n",
        "# and that it has a \"predict\" function for consistency\n",
        "\n",
        "model=joblib.load(model_file)\n",
        "predic_func=model.predict\n",
        "\n",
        "\n",
        "model_file.close()"
      ],
      "metadata": {
        "id": "r9T6Op4vlBih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOADING DATA #\n",
        "################\n",
        "\n",
        "\n",
        "#######\n",
        "# TODO:\n",
        "# You can load your data from a .csv file using numpy or pandas functions\n",
        "# IMPORTANT: your data must have a header file\n",
        "#######\n",
        "import pandas as pd\n",
        "data=pd.read_csv(\"path_to_data\",header=0) \n",
        "\n",
        "\n",
        "#######\n",
        "# (OPTIONAL):\n",
        "# If you have to do any processing of the data, please do it here. \n",
        "# But keep in mind that when you upload the data file for the explainer \n",
        "# to the iSee platform, the data should be already processed.\n",
        "#######\n"
      ],
      "metadata": {
        "id": "kGwODGyhwe-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's possible that you need to know certain characteristics of the model to execute the explainer. You will be able to access them from the configuration file of the model. We provide some examples of the file structure so you can refer to the information you need from the explainer. You will need to define the characteristics of your model following these examples. **Please keep in mind that the order of the features should match the order expected by your model.**\n"
      ],
      "metadata": {
        "id": "uiHyw2d9fOpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFIG FILE EXAMPLES #\n",
        "########################\n",
        "\n",
        "\n",
        "# TABULAR DATA\n",
        "{\n",
        "    \n",
        "  \"attributes\": {\n",
        "      \n",
        "      \"target_names\": [ \"Feature_3\" ],  # Contains the name of the target feature/s\n",
        "\n",
        "      \"features\": { # Dictionary where the keys are the feature names, and the values contain information about that feature\n",
        "          \n",
        "            \"Feature_1\": {\n",
        "              \"data_type\": \"numerical\",   # For continuous numerical values, the data_type must be \"numerical\"\n",
        "              \"min\": 0,\n",
        "              \"max\": 1,\n",
        "              \"min_raw\": 13,\n",
        "              \"max_raw\": 84\n",
        "            },\n",
        "\n",
        "            \"Feature_2\": {\n",
        "              \"data_type\": \"numerical\",\n",
        "              \"min\": 0,    # minimum value expected by the model \n",
        "              \"max\": 1,    # maximum value expected by the model\n",
        "              \"min_raw\": 10,  # If data was normalized, we can use these attributes to denormalize it in case we need to \n",
        "              \"max_raw\": 32   # It's also possible to denormalize using mean and standard deviation. Please refer to the image data example\n",
        "\n",
        "            },\n",
        "\n",
        "            \"Feature_3\": {\n",
        "                \"data_type\": \"categorical\",   # For categorical variables\n",
        "                \"values\": [ 0, 1 ],   # The encoded values for the categories as expected by the model\n",
        "                \"values_raw\": [ \"No\", \"Yes\" ]   # The real names of the categories. This is useful to create better explanations\n",
        "           }\n",
        "      \n",
        "      }\n",
        "      \n",
        "  }\n",
        "\n",
        "},\n",
        "\n",
        "\n",
        "# IMAGE DATA\n",
        "\n",
        "{\n",
        "  \"attributes\": {\n",
        "\n",
        "    \"target_names\": [ \"label\" ], # Contains the name of the target feature/s \n",
        "\n",
        "    \"features\": {   # Dictionary where the keys are the feature names, and the values contain information about that feature\n",
        "        \n",
        "        \"image\": {  # For images, the name of the main feature will alwats be \"image\"\n",
        "            \"data_type\": \"image\", \n",
        "            \"shape\": [320, 320, 3], # This is the shape expected by the model (not including the batch size)\n",
        "            \"shape_raw\": [320, 320, 3], # This is the actual shape of the raw image. In some cases, the raw image has a different shape than the one fed to the model\n",
        "            \"mean_raw\": 45.46098,   # If data was normalized, we can use these attributes to denormalize it in case we need to \n",
        "            \"std_raw\": 50.87204     # It's also possible to denormalize using min and max values. Please refer to the tabular data example.\n",
        "        },\n",
        "\n",
        "        \"label\": {\n",
        "          \"data_type\": \"categorical\", # For categorical variables\n",
        "          \"values\": [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ], # The encoded values for the categories as expected by the model\n",
        "          \"values_raw\": [ \"Zero\", \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\" ]  # The real names of the categories. This is useful to create better explanations\n",
        "      }\n",
        "    }\n",
        "\n",
        "  }\n",
        "\n",
        "},\n",
        "\n",
        "# TEXT DATA\n",
        "{\n",
        "  \"attributes\": {\n",
        "      \n",
        "      \"target_names\": [ \"target\" ],\n",
        "\n",
        "      \"features\": {\n",
        "          \n",
        "        \"text\": { # For text, the name of the main feature will alwats be \"text\". Currently no addiotional information is given.\n",
        "            \"data_type\":\"text\"\n",
        "        }, \n",
        "    \n",
        "        \"target\": {\n",
        "          \"data_type\": \"categorical\", # For categorical variables\n",
        "          \"values\": [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19 ], # The encoded values for the categories as expected by the model\n",
        "          \"values_raw\": [ \"atheism\", \"graphics\", \"ms-windows.misc\", \"pc.hardware\", \"mac.hardware\", \"x\", \n",
        "                         \"misc.forsale\", \"autos\", \"motorcycles\", \"baseball\", \"hockey\", \"crypt\", \"electronics\", \n",
        "                         \"med\", \"space\", \"christian\", \"guns\", \"mideast\", \"politics.misc\", \"religion.misc\" ] # The real names of the categories. This is useful to create better explanations\n",
        "        } \n",
        "      }\n",
        "    }\n",
        "},\n",
        "\n",
        "# TIME SERIES DATA\n",
        "# This format is very similar to the tabular data example, but with a special attribute: \"window_size\".\n",
        "\n",
        "{\n",
        "    \n",
        "  \"attributes\": {\n",
        "      \n",
        "      \"target_names\": [ \"Feature_3\" ],  # Contains the name of the target feature/s\n",
        "\n",
        "      \"window_size\": 14,  # The number of data instances per time window\n",
        "\n",
        "      \"features\": { # Dictionary where the keys are the feature names, and the values contain information about that feature\n",
        "          \n",
        "            \"Feature_0\": {\n",
        "              \"data_type\": \"time\"   # To identify the time-related feature\n",
        "            },\n",
        "\n",
        "            \"Feature_1\": {\n",
        "              \"data_type\": \"numerical\",   # For continuous numerical values, the data_type must be \"numerical\"\n",
        "              \"min\": 0,\n",
        "              \"max\": 1,\n",
        "              \"min_raw\": 13,\n",
        "              \"max_raw\": 84\n",
        "            },\n",
        "\n",
        "            \"Feature_2\": {\n",
        "              \"data_type\": \"numerical\",\n",
        "              \"min\": 0,    # minimum value expected by the model \n",
        "              \"max\": 1,    # maximum value expected by the model\n",
        "              \"min_raw\": 10,  # If data was normalized, we can use these attributes to denormalize it in case we need to \n",
        "              \"max_raw\": 32   # It's also possible to denormalize using mean and standard deviation. Please refer to the image data example\n",
        "\n",
        "            },\n",
        "\n",
        "            \"Feature_3\": {\n",
        "                \"data_type\": \"categorical\",   # For categorical variables\n",
        "                \"values\": [ 0, 1 ],   # The encoded values for the categories as expected by the model\n",
        "                \"values_raw\": [ \"No\", \"Yes\" ]   # The real names of the categories. This is useful to create better explanations\n",
        "           }\n",
        "      \n",
        "      }\n",
        "      \n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "#######\n",
        "# TODO:\n",
        "# Describe your model configuration\n",
        "# REMEMBER: feature order is important!\n",
        "#######\n",
        "\n",
        "model_info={}"
      ],
      "metadata": {
        "id": "qvY_-VYyfjx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Develop your explainer"
      ],
      "metadata": {
        "id": "nVIidKiklB4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we ask you write the code for your explainer. The code will be included in the *explain()* function, but you can define your own helper functions as well. You can refer to our helper functions as well at https://github.com/isee4xai/iSeeExplainerLibrary/blob/dev/utils."
      ],
      "metadata": {
        "id": "lnMjrr244MBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The explain() function takes the following parameters:\n",
        "\n",
        "    # Parameters:\n",
        "\n",
        "    # model (Object): the model object as described as described above\n",
        "    #\n",
        "    # model_info (dict): the dictionary with the model information as described above\n",
        "    #\n",
        "    # data (Pandas.DataFrame or numpy.array, optional): the training data used by the model. \n",
        "    #                                                   Please avoid data processing inside the explain function\n",
        "    #\n",
        "    # params_json (dict, optional): dictionary containing additional parameters that maybe needed for execution.\n",
        "    #                               e.g. { \"n_steps\":50, \"batch_size\": 100}\n",
        "    #                               Please assign default values for these parameters in your code whenever possible\n",
        "    #\n",
        "    # instance (-, optional): data point to be explained. The format will depend on the input expected by the model\n",
        "\n",
        "    # Returns: dictionary containing the explanation and its type/format. Currently, we accept the following formats:\n",
        "              # type:\"html\" - > string with html code\n",
        "              # type:\"image\" - > base64 encoded image (you can refer to our helper functions)\n",
        "              # type:\"dict\" - > dictionary/JSON object\n",
        "              # type:\"text\" - > plain text (string)\n",
        "                \n",
        "def explain(model, model_info, data=None, params_json=None, instance=None):\n",
        "\n",
        "  #######\n",
        "  # TODO:\n",
        "  # YOUR EXPLAINER CODE HERE\n",
        "  #######\n",
        "\n",
        "\n",
        "  \n",
        "  ret={\"type\":\"\", \"explanation\":\"\"}\n",
        "  return ret"
      ],
      "metadata": {
        "id": "YUAVDa5F4GtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can test your explain() function in the following cell by changing the parameters below."
      ],
      "metadata": {
        "id": "FuE8PmetlJKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  #######\n",
        "  # TODO:\n",
        "  # Test your explainer by replacing these values \n",
        "  # with your own values according to the description above\n",
        "  #######\n",
        "\n",
        "data=None  \n",
        "params_json={} \n",
        "instance=None \n",
        "\n",
        "output=explain(model,model_info, data, params_json, instance) \n",
        "print(output)"
      ],
      "metadata": {
        "id": "vTzKigGblLDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Add documentation for your explainer"
      ],
      "metadata": {
        "id": "620JmR2JkyfL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last step is to write the documentation for your explainer. The documentation of the explainers is available in the *get()* method. Below is an example of the expected format for the documentation."
      ],
      "metadata": {
        "id": "Dt1H8fpyEY4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DESCRIPTION EXAMPLE #\n",
        "#######################\n",
        "\n",
        "def get(self):\n",
        "    return {\n",
        "    \"_method_description\": \"Displays the SHAP interaction values of a feature. Only supports scikit-learn-based models. This method accepts 2 argument: \" \n",
        "                        \"the model 'id', and the 'params' JSON with the configuration parameters of the method. \",\n",
        "    \"id\": \"Identifier of the ML model that was stored locally.\",\n",
        "    \"params\": {  # For each of the parameters of your explainer in params_json\n",
        "            \"feature\": {\n",
        "                \"description\":\"Name of the feature which will be used to calculate the SHAP interaction values. Defaults to the feature with the highest average SHAP value.\",\n",
        "                \"type\": \"string\",  #possible types: string, int, float, array, dict.\n",
        "                \"default\": None, # default value of the parameter\n",
        "                \"range\":[], # use when values are within a range e.g [0,1] or when there is a fixed set of accepted values e.g ['mean','median','mode']\n",
        "                \"required\": False  # If the parameter is required for the explainer to execute. Please try to include default values in your code so parameter aren't strictly required\n",
        "                },\n",
        "            },\n",
        "    \"output_description\":{\n",
        "            \"bar_plot\": \"The bar plot shows the SHAP interaction values with the other features for the selected feature.\"\n",
        "      },\n",
        "    \"meta\":{\n",
        "            \"supportsAPI\":False, # ignore\n",
        "            \"needsData\": True   # explainer needs training data\n",
        "        }\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "EBoKDcyPk01s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, include the description of your explainer in your own *get()* method"
      ],
      "metadata": {
        "id": "k8SUkqpBsja3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  #######\n",
        "  # TODO:\n",
        "  # Describe your explainer in the documentation\n",
        "  # Fill in the dictionary below with your values\n",
        "  # or replace the values accordingly\n",
        "  #######\n",
        "\n",
        "def get(self):\n",
        "    return {\n",
        "    \"_method_description\": \"\", # TODO\n",
        "    \"id\": \"Identifier of the ML model that was stored locally.\",\n",
        "    \"params\": {}, # TODO\n",
        "    \"output_description\":{}, # TODO\n",
        "    \"meta\":{\n",
        "            \"supportsAPI\":False,\n",
        "            \"needsData\": None,   # TODO If the explainer needs the training data\n",
        "            \"supportsB&WImage\": None, # TODO If the explainer supports black & white images (only for image explainers)\n",
        "            \"needsMin&Max\": None, # TODO If the explainer needs min and max values in the configuration file\n",
        "        }\n",
        "    }"
      ],
      "metadata": {
        "id": "x86rETuBBaZb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}