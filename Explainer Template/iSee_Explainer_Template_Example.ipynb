{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# iSee Explainer Template (Example)"
      ],
      "metadata": {
        "id": "-9y_8nLAk4Rm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Load sample model, data and additional information"
      ],
      "metadata": {
        "id": "7W5sTfsYk7LQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We support models with different implementation frameworks such as Scikit-learn, Tensorflow, Pytorch and others. You can load your model by using the recommended approach of your framework."
      ],
      "metadata": {
        "id": "g_VCymgjt5Nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOADING MODEL #\n",
        "#################\n",
        "import urllib.request\n",
        "\n",
        "#######\n",
        "# TODO:\n",
        "# Load your model file here. \n",
        "# You may do so via google drive\n",
        "#######\n",
        "urllib.request.urlretrieve(\"https://github.com/XCBRChallenge/2023-utils/raw/main/INCOME.pkl\", \"INCOME.pkl\")\n",
        "model_file=open(\"INCOME.pkl\",'rb') \n",
        "\n",
        "#######\n",
        "# TODO:\n",
        "# Choose how to load your model. \n",
        "# Comment the rest of options\n",
        "#######\n",
        "\n",
        "# For scikit-learn\n",
        "import joblib\n",
        "model=joblib.load(model_file)\n",
        "\n",
        "# For tensorflow\n",
        "#import tensorflow as tf\n",
        "#model=tf.keras.models.load_model(model_file)\n",
        "\n",
        "#For Pytorch\n",
        "#import torch\n",
        "#model=torch.load(model_file)\n",
        "\n",
        "# For different implementations, please make sure the model object can be loaded with joblib\n",
        "# and that it has a \"predict\" function for consistency\n",
        "\n",
        "#model=joblib.load(model_file)\n",
        "#predic_func=model.predict\n",
        "\n",
        "model_file.close()"
      ],
      "metadata": {
        "id": "r9T6Op4vlBih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ed7e9de-d10d-49e4-9bf6-cbcc20e75a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOADING DATA #\n",
        "################\n",
        "\n",
        "\n",
        "#######\n",
        "# TODO:\n",
        "# You can load your data from a .csv file using numpy or pandas functions\n",
        "# IMPORTANT: your data must have a header file\n",
        "#######\n",
        "import pandas as pd\n",
        "urllib.request.urlretrieve(\"https://github.com/XCBRChallenge/2023-utils/raw/main/INCOME_data.csv\", \"INCOME_data.csv\")\n",
        "\n",
        "data=pd.read_csv(\"INCOME_data.csv\",header=0) \n",
        "\n",
        "\n",
        "#######\n",
        "# (OPTIONAL):\n",
        "# If you have to do any processing of the data, please do it here. \n",
        "# But keep in mind that when you upload the data file for the explainer \n",
        "# to the iSee platform, the data should be already processed.\n",
        "#######\n"
      ],
      "metadata": {
        "id": "kGwODGyhwe-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's possible that you need to know certain characteristics of the model to execute the explainer. You will be able to access them from the configuration file of the model. We provide some examples of the file structure so you can refer to the information you need from the explainer. You will need to define the characteristics of your model following these examples. **Please keep in mind that the order of the features should match the order expected by your model.**\n"
      ],
      "metadata": {
        "id": "uiHyw2d9fOpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFIG FILE EXAMPLES #\n",
        "########################\n",
        "\n",
        "\n",
        "# TABULAR DATA\n",
        "{\n",
        "    \n",
        "  \"attributes\": {\n",
        "      \n",
        "      \"target_names\": [ \"Feature_3\" ],  # Contains the name of the target feature/s\n",
        "\n",
        "      \"features\": { # Dictionary where the keys are the feature names, and the values contain information about that feature\n",
        "          \n",
        "            \"Feature_1\": {\n",
        "              \"data_type\": \"numerical\",   # For continuous numerical values, the data_type must be \"numerical\"\n",
        "              \"min\": 0,\n",
        "              \"max\": 1,\n",
        "              \"min_raw\": 13,\n",
        "              \"max_raw\": 84\n",
        "            },\n",
        "\n",
        "            \"Feature_2\": {\n",
        "              \"data_type\": \"numerical\",\n",
        "              \"min\": 0,    # minimum value expected by the model \n",
        "              \"max\": 1,    # maximum value expected by the model\n",
        "              \"min_raw\": 10,  # If data was normalized, we can use these attributes to denormalize it in case we need to \n",
        "              \"max_raw\": 32   # It's also possible to denormalize using mean and standard deviation. Please refer to the image data example\n",
        "\n",
        "            },\n",
        "\n",
        "            \"Feature_3\": {\n",
        "                \"data_type\": \"categorical\",   # For categorical variables\n",
        "                \"values\": [ 0, 1 ],   # The encoded values for the categories as expected by the model\n",
        "                \"values_raw\": [ \"No\", \"Yes\" ]   # The real names of the categories. This is useful to create better explanations\n",
        "           }\n",
        "      \n",
        "      }\n",
        "      \n",
        "  }\n",
        "\n",
        "},\n",
        "\n",
        "\n",
        "# IMAGE DATA\n",
        "\n",
        "{\n",
        "  \"attributes\": {\n",
        "\n",
        "    \"target_names\": [ \"label\" ], # Contains the name of the target feature/s \n",
        "\n",
        "    \"features\": {   # Dictionary where the keys are the feature names, and the values contain information about that feature\n",
        "        \n",
        "        \"image\": {  # For images, the name of the main feature will alwats be \"image\"\n",
        "            \"data_type\": \"image\", \n",
        "            \"shape\": [320, 320, 3], # This is the shape expected by the model (not including the batch size)\n",
        "            \"shape_raw\": [320, 320, 3], # This is the actual shape of the raw image. In some cases, the raw image has a different shape than the one fed to the model\n",
        "            \"mean_raw\": 45.46098,   # If data was normalized, we can use these attributes to denormalize it in case we need to \n",
        "            \"std_raw\": 50.87204     # It's also possible to denormalize using min and max values. Please refer to the tabular data example.\n",
        "        },\n",
        "\n",
        "        \"label\": {\n",
        "          \"data_type\": \"categorical\", # For categorical variables\n",
        "          \"values\": [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ], # The encoded values for the categories as expected by the model\n",
        "          \"values_raw\": [ \"Zero\", \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\" ]  # The real names of the categories. This is useful to create better explanations\n",
        "      }\n",
        "    }\n",
        "\n",
        "  }\n",
        "\n",
        "},\n",
        "\n",
        "# TEXT DATA\n",
        "{\n",
        "  \"attributes\": {\n",
        "      \n",
        "      \"target_names\": [ \"target\" ],\n",
        "\n",
        "      \"features\": {\n",
        "          \n",
        "        \"text\": { # For text, the name of the main feature will alwats be \"text\". Currently no addiotional information is given.\n",
        "            \"data_type\":\"text\"\n",
        "        }, \n",
        "    \n",
        "        \"target\": {\n",
        "          \"data_type\": \"categorical\", # For categorical variables\n",
        "          \"values\": [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19 ], # The encoded values for the categories as expected by the model\n",
        "          \"values_raw\": [ \"atheism\", \"graphics\", \"ms-windows.misc\", \"pc.hardware\", \"mac.hardware\", \"x\", \n",
        "                         \"misc.forsale\", \"autos\", \"motorcycles\", \"baseball\", \"hockey\", \"crypt\", \"electronics\", \n",
        "                         \"med\", \"space\", \"christian\", \"guns\", \"mideast\", \"politics.misc\", \"religion.misc\" ] # The real names of the categories. This is useful to create better explanations\n",
        "        } \n",
        "      }\n",
        "    }\n",
        "},\n",
        "\n",
        "# TIME SERIES DATA\n",
        "# This format is very similar to the tabular data example, but with a special attribute: \"window_size\".\n",
        "\n",
        "{\n",
        "    \n",
        "  \"attributes\": {\n",
        "      \n",
        "      \"target_names\": [ \"Feature_3\" ],  # Contains the name of the target feature/s\n",
        "\n",
        "      \"window_size\": 14,  # The number of data instances per time window\n",
        "\n",
        "      \"features\": { # Dictionary where the keys are the feature names, and the values contain information about that feature\n",
        "          \n",
        "            \"Feature_0\": {\n",
        "              \"data_type\": \"time\"   # To identify the time-related feature\n",
        "            },\n",
        "\n",
        "            \"Feature_1\": {\n",
        "              \"data_type\": \"numerical\",   # For continuous numerical values, the data_type must be \"numerical\"\n",
        "              \"min\": 0,\n",
        "              \"max\": 1,\n",
        "              \"min_raw\": 13,\n",
        "              \"max_raw\": 84\n",
        "            },\n",
        "\n",
        "            \"Feature_2\": {\n",
        "              \"data_type\": \"numerical\",\n",
        "              \"min\": 0,    # minimum value expected by the model \n",
        "              \"max\": 1,    # maximum value expected by the model\n",
        "              \"min_raw\": 10,  # If data was normalized, we can use these attributes to denormalize it in case we need to \n",
        "              \"max_raw\": 32   # It's also possible to denormalize using mean and standard deviation. Please refer to the image data example\n",
        "\n",
        "            },\n",
        "\n",
        "            \"Feature_3\": {\n",
        "                \"data_type\": \"categorical\",   # For categorical variables\n",
        "                \"values\": [ 0, 1 ],   # The encoded values for the categories as expected by the model\n",
        "                \"values_raw\": [ \"No\", \"Yes\" ]   # The real names of the categories. This is useful to create better explanations\n",
        "           }\n",
        "      \n",
        "      }\n",
        "      \n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "#######\n",
        "# TODO:\n",
        "# Describe your model configuration\n",
        "# REMEMBER: feature order is important!\n",
        "#######\n",
        "\n",
        "model_info={\n",
        "    \n",
        "  \"attributes\": {\n",
        "      \n",
        "    \"features\": {\n",
        "      \"annual_inc\": {\n",
        "        \"data_type\": \"numerical\",\n",
        "        \"max\": 1,\n",
        "        \"max_raw\": 700000,\n",
        "        \"min\": 0,\n",
        "        \"min_raw\": 3600\n",
        "      },\n",
        "      \"home_ownership\": {\n",
        "        \"data_type\": \"categorical\",\n",
        "        \"values\": [ 0, 1, 2, 3 ],\n",
        "        \"values_raw\": [ \"RENT\", \"OEN\", \"MORTGAGE\", \"ANY\" ]\n",
        "      },\n",
        "      \"installment\": {\n",
        "        \"data_type\": \"numerical\",\n",
        "        \"max\": 1,\n",
        "        \"max_raw\": 1474.75,\n",
        "        \"min\": 0,\n",
        "        \"min_raw\": 32.47\n",
        "      },\n",
        "      \"int_rate\": {\n",
        "        \"data_type\": \"numerical\",\n",
        "        \"max\": 1,\n",
        "        \"max_raw\": 30.79,\n",
        "        \"min\": 0,\n",
        "        \"min_raw\": 5.31\n",
        "      },\n",
        "      \"loan_amnt\": {\n",
        "        \"data_type\": \"numerical\",\n",
        "        \"max\": 1,\n",
        "        \"max_raw\": 40000,\n",
        "        \"min\": 0,\n",
        "        \"min_raw\": 1000\n",
        "      },\n",
        "      \"loan_status\": {\n",
        "        \"data_type\": \"categorical\",\n",
        "        \"values\": [ 0, 1 ],\n",
        "        \"values_raw\": [ \"Rejected\", \"Accepted\" ]\n",
        "      },\n",
        "      \"purpose\": {\n",
        "        \"data_type\": \"categorical\",\n",
        "        \"values\": [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 ],\n",
        "        \"values_raw\": [ \"major purchase\", \"other\", \"home improvement\", \"debt consolidation\", \"house\", \"credit card\", \"car\", \"medical\", \"vacation\", \"small business\", \"moving\", \"renewable energy\" ]\n",
        "      },\n",
        "      \"term\": {\n",
        "        \"data_type\": \"categorical\",\n",
        "        \"values\": [ 0, 1 ],\n",
        "        \"values_raw\": [ \"36 months\", \"60 months\" ]\n",
        "      },\n",
        "      \"total_pymnt\": {\n",
        "        \"data_type\": \"numerical\",\n",
        "        \"max\": 1,\n",
        "        \"max_raw\": 44881.66051,\n",
        "        \"min\": 0,\n",
        "        \"min_raw\": 41.62\n",
        "      },\n",
        "      \"total_rec_int\": {\n",
        "        \"data_type\": \"numerical\",\n",
        "        \"max\": 1,\n",
        "        \"max_raw\": 7036.9,\n",
        "        \"min\": 0,\n",
        "        \"min_raw\": 0\n",
        "      },\n",
        "      \"verification_status\": {\n",
        "        \"data_type\": \"categorical\",\n",
        "        \"values\": [ 0, 1, 2 ],\n",
        "        \"values_raw\": [ \"Source Verified\", \"Not Verified\", \"Verified\" ]\n",
        "      }\n",
        "    },\n",
        "    \"target_names\": [ \"loan_status\" ]\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "id": "qvY_-VYyfjx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Develop your explainer"
      ],
      "metadata": {
        "id": "nVIidKiklB4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we ask you write the code for your explainer. The code will be included in the *explain()* function, but you can define your own helper functions as well. You can refer to our helper functions as well at https://github.com/isee4xai/iSeeExplainerLibrary/blob/dev/utils."
      ],
      "metadata": {
        "id": "lnMjrr244MBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install NICEx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkskuLbc0vIW",
        "outputId": "73e9102f-7d57-463b-f7ce-19150148b081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting NICEx\n",
            "  Downloading NICEx-0.2.3-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: pandas<2.0.0,>=0.23.3 in /usr/local/lib/python3.10/dist-packages (from NICEx) (1.5.3)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from NICEx) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=0.23.3->NICEx) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=0.23.3->NICEx) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<2.0.0,>=0.23.3->NICEx) (1.16.0)\n",
            "Installing collected packages: NICEx\n",
            "Successfully installed NICEx-0.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from nice import NICE"
      ],
      "metadata": {
        "id": "W9vbPSAnz_WI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility function from https://github.com/isee4xai/iSeeExplainerLibrary/blob/dev/utils\n",
        "\n",
        "def denormalize_dataframe(df,model_info):\n",
        "    denorm_df=df.copy()\n",
        "    column_names=list(denorm_df.columns)\n",
        "    for feature in column_names:\n",
        "        feature_dict=model_info[\"attributes\"][\"features\"][feature]\n",
        "        if(feature_dict[\"data_type\"]==\"numerical\"):\n",
        "            if(\"min\" in feature_dict and \"max\" in feature_dict and \"min_raw\" in feature_dict and \"max_raw\" in feature_dict):\n",
        "                nmin=feature_dict[\"min\"]\n",
        "                nmax=feature_dict[\"max\"]\n",
        "                min_raw=feature_dict[\"min_raw\"]\n",
        "                max_raw=feature_dict[\"max_raw\"]\n",
        "                try:\n",
        "                    denorm_df[feature]=(((denorm_df[feature]-nmin)/(nmax-nmin))*(max_raw-min_raw)+min_raw)\n",
        "                except:\n",
        "                    raise\n",
        "            elif (\"mean_raw\" in feature_dict and \"std_raw\" in feature_dict):\n",
        "                mean=np.array(feature_dict[\"mean_raw\"])\n",
        "                std=np.array(feature_dict[\"std_raw\"])\n",
        "                try:\n",
        "                    denorm_df[feature]=((denorm_df[feature]*std)+mean)\n",
        "                except Exception as e:\n",
        "                    raise\n",
        "        elif feature_dict[\"data_type\"]==\"categorical\":\n",
        "            if(\"values\" in feature_dict and \"values_raw\" in feature_dict):\n",
        "                try:\n",
        "                    denorm_df[feature]=denorm_df[feature].apply(lambda row: feature_dict[\"values_raw\"][int(row)])\n",
        "                except:\n",
        "                    pass\n",
        "            elif(\"value\" in feature_dict and \"ohe_feature\" in feature_dict):\n",
        "                if(denorm_df[feature].values[0]==0):\n",
        "                    denorm_df=denorm_df.drop(feature,axis=1)\n",
        "                else:\n",
        "                    denorm_df[feature]=feature_dict[\"value\"]\n",
        "                    denorm_df=denorm_df.rename(columns={feature: feature_dict[\"ohe_feature\"]})\n",
        "                                        \n",
        "    return denorm_df"
      ],
      "metadata": {
        "id": "xTlX-V2T1f5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The explain() function takes the following parameters:\n",
        "\n",
        "    # Parameters:\n",
        "\n",
        "    # model (Object): the model object as described above\n",
        "    #\n",
        "    # model_info (dict): the dictionary with the model information as described above\n",
        "    #\n",
        "    # data (Pandas.DataFrame or numpy.array, optional): the training data used by the model. \n",
        "    #                                                   Please avoid data processing inside the explain function\n",
        "    #\n",
        "    # params_json (dict, optional): dictionary containing additional parameters that maybe needed for execution.\n",
        "    #                               e.g. { \"n_steps\":50, \"batch_size\": 100}\n",
        "    #                               Please assign default values for these parameters in your code whenever possible\n",
        "    #\n",
        "    # instance (-, optional): data point to be explained. The format will depend on the input expected by the model\n",
        "\n",
        "    # Returns: dictionary containing the explanation and its type/format. Currently, we accept the following formats:\n",
        "              # type:\"html\" - > string with html code\n",
        "              # type:\"image\" - > base64 encoded image (you can refer to our helper functions)\n",
        "              # type:\"dict\" - > dictionary/JSON object\n",
        "              # type:\"text\" - > plain text (string)\n",
        "                \n",
        "def explain(model, model_info, data=None, params_json=None, instance=None):\n",
        "\n",
        "  #######\n",
        "  # TODO:\n",
        "  # YOUR EXPLAINER CODE HERE\n",
        "  #######\n",
        "\n",
        "  # getting necessary data from model info\n",
        "  target_name=model_info[\"attributes\"][\"target_names\"][0]\n",
        "  features=model_info[\"attributes\"][\"features\"]\n",
        "  feature_names=list(features.keys())\n",
        "\n",
        "  X=data.drop([target_name], axis=1, inplace=False).values\n",
        "  y=data.loc[:,target_name].values\n",
        "\n",
        "  feature_names.remove(target_name)\n",
        "  categorical_features=[]\n",
        "  for feature in feature_names:\n",
        "      if features[feature][\"data_type\"]==\"categorical\":\n",
        "          categorical_features.append(data.columns.get_loc(feature))\n",
        "\n",
        "\n",
        "  # Getting prediction for instance\n",
        "  pred_func=model.predict_proba\n",
        "  instance_pred=np.array(pred_func(instance)[0])\n",
        "\n",
        "  # Getting parameters from json\n",
        "  optimization_criteria=\"sparsity\"\n",
        "  desired_class=\"other\"\n",
        "  if \"optimization_criteria\" in params_json and params_json[\"optimization_criteria\"] in [\"sparsity\",\"proximity\",\"plausibility\"]:\n",
        "      optimization_criteria = params_json[\"optimization_criteria\"]\n",
        "  if \"desired_class\" in params_json:\n",
        "      try: \n",
        "          u_class=int(params_json[\"desired_class\"])\n",
        "          if u_class >= 0 and u_class < instance_pred.shape[-1]:\n",
        "              desired_class=[u_class]\n",
        "      except:\n",
        "          pass\n",
        "\n",
        "  # Generate counterfactuals\n",
        "  NICE_res = NICE(pred_func,X,categorical_features,y_train=y,optimization=optimization_criteria)\n",
        "  CF = NICE_res.explain(instance,target_class=desired_class)[0]\n",
        "\n",
        "  instance_row=np.array(np.append(instance,np.argmax(instance_pred)))\n",
        "  cf_row=np.array(list(CF)+[np.argmax(pred_func([CF])[0])])\n",
        "\n",
        "  df = pd.DataFrame(data = np.array([instance_row,cf_row]), \n",
        "            index = [\"Original Instance\",\"Counterfactual\"], \n",
        "            columns = feature_names + [target_name])\n",
        "  \n",
        "  # denormalizing for a more interpretable output\n",
        "  # using one of the utility functions from the iSee repo\n",
        "  df_norm=denormalize_dataframe(df,model_info)\n",
        "\n",
        "\n",
        "  ret={\"type\":\"html\", \"explanation\":df_norm.to_html()}\n",
        "  return ret"
      ],
      "metadata": {
        "id": "YUAVDa5F4GtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can test your explain() function in the following cell by changing the parameters below."
      ],
      "metadata": {
        "id": "FuE8PmetlJKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  #######\n",
        "  # TODO:\n",
        "  # Test your explainer by replacing these values \n",
        "  # with your own values according to the description above\n",
        "  #######\n",
        "\n",
        "data=data  \n",
        "params_json={\"optimization_criteria\":\"proximity\"} \n",
        "instance=data.iloc[[0]].drop([\"loan_status\"],axis=1).to_numpy()\n",
        "\n",
        "output=explain(model,model_info, data, params_json, instance) \n",
        "print(output)"
      ],
      "metadata": {
        "id": "vTzKigGblLDh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "682f7f19-d319-47c1-abe0-a5ab542e79fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'type': 'html', 'explanation': '<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>annual_inc</th>\\n      <th>home_ownership</th>\\n      <th>installment</th>\\n      <th>int_rate</th>\\n      <th>loan_amnt</th>\\n      <th>purpose</th>\\n      <th>term</th>\\n      <th>total_pymnt</th>\\n      <th>total_rec_int</th>\\n      <th>verification_status</th>\\n      <th>loan_status</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>Original Instance</th>\\n      <td>200020.512821</td>\\n      <td>RENT</td>\\n      <td>147.95242</td>\\n      <td>5.31</td>\\n      <td>15892.857143</td>\\n      <td>major purchase</td>\\n      <td>60 months</td>\\n      <td>2127.802241</td>\\n      <td>0.0</td>\\n      <td>Source Verified</td>\\n      <td>Rejected</td>\\n    </tr>\\n    <tr>\\n      <th>Counterfactual</th>\\n      <td>200020.512821</td>\\n      <td>RENT</td>\\n      <td>147.95242</td>\\n      <td>5.31</td>\\n      <td>15892.857143</td>\\n      <td>major purchase</td>\\n      <td>60 months</td>\\n      <td>2127.802241</td>\\n      <td>0.0</td>\\n      <td>Source Verified</td>\\n      <td>Accepted</td>\\n    </tr>\\n  </tbody>\\n</table>'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "IPython.display.HTML(data=output[\"explanation\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "9h9oJC723GKN",
        "outputId": "41168bc5-42ee-4204-aec4-ea06a22ac6d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annual_inc</th>\n",
              "      <th>home_ownership</th>\n",
              "      <th>installment</th>\n",
              "      <th>int_rate</th>\n",
              "      <th>loan_amnt</th>\n",
              "      <th>purpose</th>\n",
              "      <th>term</th>\n",
              "      <th>total_pymnt</th>\n",
              "      <th>total_rec_int</th>\n",
              "      <th>verification_status</th>\n",
              "      <th>loan_status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Original Instance</th>\n",
              "      <td>200020.512821</td>\n",
              "      <td>RENT</td>\n",
              "      <td>147.95242</td>\n",
              "      <td>5.31</td>\n",
              "      <td>15892.857143</td>\n",
              "      <td>major purchase</td>\n",
              "      <td>60 months</td>\n",
              "      <td>2127.802241</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Source Verified</td>\n",
              "      <td>Rejected</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Counterfactual</th>\n",
              "      <td>200020.512821</td>\n",
              "      <td>RENT</td>\n",
              "      <td>147.95242</td>\n",
              "      <td>5.31</td>\n",
              "      <td>15892.857143</td>\n",
              "      <td>major purchase</td>\n",
              "      <td>60 months</td>\n",
              "      <td>2127.802241</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Source Verified</td>\n",
              "      <td>Accepted</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Add documentation for your explainer"
      ],
      "metadata": {
        "id": "620JmR2JkyfL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last step is to write the documentation for your explainer. The documentation of the explainers is available in the *get()* method. Below is an example of the expected format for the documentation."
      ],
      "metadata": {
        "id": "Dt1H8fpyEY4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DESCRIPTION EXAMPLE #\n",
        "#######################\n",
        "\n",
        "def get(self):\n",
        "    return {\n",
        "    \"_method_description\": \"Displays the SHAP interaction values of a feature. Only supports scikit-learn-based models. This method accepts 2 argument: \" \n",
        "                        \"the model 'id', and the 'params' JSON with the configuration parameters of the method. \",\n",
        "    \"id\": \"Identifier of the ML model that was stored locally.\",\n",
        "    \"params\": {  # For each of the parameters of your explainer in params_json\n",
        "            \"feature\": {\n",
        "                \"description\":\"Name of the feature which will be used to calculate the SHAP interaction values. Defaults to the feature with the highest average SHAP value.\",\n",
        "                \"type\": \"string\",  #possible types: string, int, float, array, dict.\n",
        "                \"default\": None, # default value of the parameter\n",
        "                \"range\":[], # use when values are within a range e.g [0,1] or when there is a fixed set of accepted values e.g ['mean','median','mode']\n",
        "                \"required\": False  # If the parameter is required for the explainer to execute. Please try to include default values in your code so parameter aren't strictly required\n",
        "                },\n",
        "            },\n",
        "    \"output_description\":{\n",
        "            \"bar_plot\": \"The bar plot shows the SHAP interaction values with the other features for the selected feature.\"\n",
        "      },\n",
        "    \"meta\":{\n",
        "            \"supportsAPI\":False, # ignore\n",
        "            \"needsData\": True   # explainer needs training data\n",
        "        }\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "EBoKDcyPk01s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, include the description of your explainer in your own *get()* method"
      ],
      "metadata": {
        "id": "k8SUkqpBsja3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  #######\n",
        "  # TODO:\n",
        "  # Describe your explainer in the documentation\n",
        "  # Fill in the dictionary below with your values\n",
        "  # or replace the values accordingly\n",
        "  #######\n",
        "\n",
        "def get(self):\n",
        "    return {\n",
        "    \"_method_description\": \"NICE is an algorithm to generate Counterfactual Explanations for heterogeneous tabular data.\"\n",
        "                            \"NICE exploits information from a nearest instance to speed up the search process and guarantee that an explanation will be found. Accepts the following arguments: \" \n",
        "                            \"the 'id' string, the 'instance', and the 'params' dictionary (optional) containing the configuration parameters of the explainer.\"\n",
        "                            \" These arguments are described below.\",\n",
        "    \"id\": \"Identifier of the ML model that was stored locally.\",\n",
        "    \"instance\": \"Row with the feature values of an instance (not including the target class).\",\n",
        "    \"params\": { \n",
        "            \"desired_class\": {\n",
        "                \"description\": \"Integer representing the index of the desired counterfactual class. Defaults to string 'other', which will look for any different class.\",\n",
        "                \"type\":\"int\",\n",
        "                \"default\": None,\n",
        "                \"range\":None,\n",
        "                \"required\":False\n",
        "                },\n",
        "            \"optimization_criteria\":{\n",
        "                \"description\": \"The counterfactual criteria to optimize.\",\n",
        "                \"type\":\"string\",\n",
        "                \"default\": \"sparsity\",\n",
        "                \"range\":[\"sparsity\",\"proximity\",\"plausibility\"],\n",
        "                \"required\":False\n",
        "                } \n",
        "            },\n",
        "    \"output_description\":{\n",
        "            \"html_table\": \"An html page containing a table with the original instance compared against the generated counterfactual.\"\n",
        "            },\n",
        "    \"meta\":{\n",
        "            \"supportsAPI\":False,\n",
        "            \"needsData\": True,\n",
        "            \"needsMin&Max\": False\n",
        "\n",
        "        }\n",
        "    }"
      ],
      "metadata": {
        "id": "x86rETuBBaZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0wDAJBBvi8LA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}